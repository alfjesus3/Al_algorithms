{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bitcs231ncondaf16277106f4b4993b0df2b223340cc8c",
   "display_name": "Python 3.7.9 64-bit ('cs231n': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(601, 800, 3)\n(800, 3)\n[[113 154 206]\n [116 157 209]\n [117 159 209]\n [113 155 205]\n [109 150 204]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = imread('./data/bulld.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "print(img.shape)\n",
    "print(img[0].shape)\n",
    "print(img[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The weights shape is (10, 22, 22, 3) and biases shape is (10, 1)\n",
      "(22, 22, 3)\n",
      "The output volume shape is (151, 196, 10)\n",
      "\n",
      "[[[1330407.4187215  1195493.15730372 1059510.73270879  924149.0855602\n",
      "    789616.76798194  660617.77471458  529231.35211964  396691.8529326\n",
      "    262718.08538522  132275.13347974]\n",
      "  [1337604.09159686 1201877.47391614 1065205.04047298  929130.3568367\n",
      "    793863.18107336  664158.92392204  532068.16703962  398830.9398846\n",
      "    264095.9936101   132931.45458364]]\n",
      "\n",
      " [[1342462.04545641 1206211.7288681  1069170.21322827  932714.81313622\n",
      "    796887.10017989  666696.0990414   534058.93771923  400399.74574183\n",
      "    265221.60694619  133586.53778719]\n",
      "  [1345924.50710304 1209364.54515611 1071912.37375292  935115.05621883\n",
      "    798999.71937799  668473.99480967  535512.32407198  401473.89646173\n",
      "    265962.68680469  133945.44053794]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def assess_output_vol(input_size, fi, s, padd, K):\n",
    "    \"\"\"\n",
    "        Computes the suitable output volume given S, F, P and K\n",
    "        Assumes a squared filter\n",
    "    \"\"\"\n",
    "\n",
    "    on_h_axis = (input_size[0]-fi + 2*padd[0])/(s) + 1\n",
    "    assert on_h_axis == int(on_h_axis), \"The height axis requires padding : {}\".format(on_h_axis)\n",
    "    on_w_axis = (input_size[1]-fi + 2*padd[1])/(s) + 1\n",
    "    assert on_w_axis == int(on_w_axis),\"The width axis requires padding : {}\".format(on_w_axis)\n",
    "    on_d_axis = K\n",
    "    #print(f'The dimensions of the output volume are \\\n",
    "    #    {on_h_axis} by {on_w_axis} by {on_d_axis}.')\n",
    "    return (int(on_h_axis), int(on_w_axis), on_d_axis)\n",
    "\n",
    "def convolutional_layer1(img, filter_size, stride, padding, K):\n",
    "    \"\"\"\n",
    "        Receives a image (H*W*3)\n",
    "        The kernel size is filter_size*filter_size*3\n",
    "        The weights are learned by the CNN where each \"slice\" is a filter\n",
    "        The depth of the output map is represented by K\n",
    "\n",
    "        Returns:\n",
    "            Activation map applying the filter to the input\n",
    "    \"\"\"\n",
    "    weights = np.random.rand(K, filter_size, filter_size, img.shape[2])\n",
    "    biases = np.random.rand(K, 1)\n",
    "    print(f'The weights shape is {weights.shape} and biases shape is {biases.shape}')\n",
    "    print(weights[0,:,:,:].shape) # filter0 or weight0\n",
    "\n",
    "    out_dims = assess_output_vol(img.shape, filter_size, stride, padding,K)\n",
    "\n",
    "    activation_map = np.zeros(out_dims)\n",
    "    assert activation_map.shape == out_dims\n",
    "\n",
    "    for d in range(out_dims[2]):\n",
    "        for i in range(0,out_dims[0],stride):\n",
    "            for j in range(0,out_dims[1],stride):\n",
    "                activation_map[int(i/4),int(j/4),d] = np.sum(img[i:i+filter_size,j:j+filter_size,:] * weights[d:,:,:]) + biases[d]\n",
    "    \n",
    "    print(f'The output volume shape is {activation_map.shape}\\n')\n",
    "\n",
    "    return activation_map\n",
    "\n",
    "K = 10 # depth of output map\n",
    "\n",
    "# Testing for suitable strides\n",
    "assess_output_vol((11,11,3), 5, 2, [0,0], K)\n",
    "assess_output_vol(img.shape, 22, 4, [21/2,1], K)\n",
    "# Passing the image through a basic convolution layer\n",
    "activn_map_conv = convolutional_layer1(img, 22, 4, [21/2,1], K)\n",
    "print(activn_map_conv[:2,:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(151, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "def find_volume_pooling(input_size, F, S):\n",
    "    \"\"\"\n",
    "        Given the input size (H,W,D) it calculates \n",
    "            the output volume (H',W',D) by the pooling operation\n",
    "    \"\"\"\n",
    "    on_h_axis = (input_size[0] - F)/(S) + 1\n",
    "    assert on_h_axis == int(on_h_axis), \"The height axis requires padding : {}\".format(on_h_axis)\n",
    "    on_w_axis = (input_size[1] - F)/(S) + 1\n",
    "    assert on_w_axis == int(on_w_axis),\"The width axis requires padding : {}\".format(on_w_axis)\n",
    "    on_d_axis = input_size[2] # assuming (H,W,D)\n",
    "\n",
    "    return (int(on_h_axis), int(on_w_axis), on_d_axis)\n",
    "\n",
    "def pooling_layer1(input, F, S):\n",
    "    \"\"\"\n",
    "        The basic intuition is very similar to the Convolutional layer\n",
    "            expect it doesn't require weights or biases\n",
    "        The goal here is to reduce the is to \"compress\" the input volume by\n",
    "            discarding everything other than the maximum over a F * F area\n",
    "        The most common way to compress is to use a MAX operation over each filter slice\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    out_dims = find_volume_pooling(input.shape, F, S)\n",
    "    pooling_out = np.zeros(out_dims)\n",
    "\n",
    "    for d in range(input.shape[2]):\n",
    "        for i in range(0,input.shape[0],S):\n",
    "            for j in range(0,input.shape[1],S):\n",
    "                # Implementing the MAX-Pooling operation\n",
    "                pooling_out[int(i),int(j),d] = np.max(input[i:i+F,j:j+F,d])\n",
    "    \n",
    "    print(f'The output volume shape is {activation_map.shape}\\n')\n",
    "\n",
    "    return pooling_out\n",
    "\n",
    "\n",
    "F=2 # filter size by convention\n",
    "S=2 # stride by convention\n",
    "\n",
    "# Testing the output volume\n",
    "find_volume_pooling((224,224,64), F, S)\n",
    "find_volume_pooling((151+1,186,10), F, S) # It means that it requires zero-padding of 1 in the height component\n",
    "\n",
    "# adding zero padding to height - it is irrelevant to which part\n",
    "input_pooling = np.empty_like(activn_map_conv)\n",
    "#print(input_pooling.shape)\n",
    "t = np.zeros((input_pooling.shape[0],1))\n",
    "print(t.shape)\n",
    "for d in range(input_pooling.shape[2]):\n",
    "    input_pooling[:,:,d] = np.append(activn_map_conv[:,:,d], t,axis=0)\n",
    "    assert not (input_pooling[:,:,d].shape == activn_map_conv[:,:,d])\n",
    "#input_pooling = np.append(input_pooling, np.zeros((input_pooling.shape[0],1,1)),axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "# Implement fully connected layer\n",
    "# Change the loops to vectorized operations\n",
    "# Conversion from fully connected layer to CONV layer and vice-versa\n",
    "# Explore doing a small autograd engine where both pooling and convolutional layers are applied sequentially\n",
    "#"
   ]
  }
 ]
}