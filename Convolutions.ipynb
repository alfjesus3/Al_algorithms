{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37964bitcs231ncondaf16277106f4b4993b0df2b223340cc8c",
   "display_name": "Python 3.7.9 64-bit ('cs231n': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(601, 800, 3)\n(800, 3)\n[[113 154 206]\n [116 157 209]\n [117 159 209]\n [113 155 205]\n [109 150 204]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.misc import imread\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = imread('./data/bulld.jpg')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n",
    "print(img.shape)\n",
    "print(img[0].shape)\n",
    "print(img[0][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The weights shape is (10, 22, 22, 3) and biases shape is (10, 1)\n",
      "(22, 22, 3)\n",
      "The output volume shape is (151, 196, 10)\n",
      "\n",
      "[[[1339390.53763604 1207973.19209505 1071460.24142865  937533.76038371\n",
      "    803305.16984127  668083.23083711  534079.74624455  400218.40996307\n",
      "    269657.40933163  134571.48932194]\n",
      "  [1346727.59180844 1214571.65238145 1077298.57644341  942609.23587742\n",
      "    807616.47132029  671688.84537972  537035.17029588  402433.82374281\n",
      "    271170.29577879  135331.77750813]]\n",
      "\n",
      " [[1351783.90002297 1219151.69536316 1081367.97037481  945990.31297758\n",
      "    810563.04537007  674141.19217319  539013.34586852  403979.14540541\n",
      "    272028.37884428  135725.46709527]\n",
      "  [1355393.53406103 1222416.06964252 1084268.09405383  948548.08695895\n",
      "    812758.91797002  675962.74249308  540455.41161188  405070.28175456\n",
      "    272760.94096318  136072.50495358]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def assess_output_vol(img_dimens, fi, s, padd, K):\n",
    "    \"\"\"\n",
    "        Computes the suitable output volume given S, F, P and K\n",
    "        Assumes a squared filter\n",
    "    \"\"\"\n",
    "\n",
    "    on_h_axis = (img_dimens[0]-fi + 2*padd[0])/(s) + 1\n",
    "    assert on_h_axis == int(on_h_axis), \"The height axis requires padding : {}\".format(on_h_axis)\n",
    "    on_w_axis = (img_dimens[1]-fi + 2*padd[1])/(s) + 1\n",
    "    assert on_w_axis == int(on_w_axis),\"The width axis requires padding : {}\".format(on_w_axis)\n",
    "    on_d_axis = K\n",
    "    #print(f'The dimensions of the output volume are \\\n",
    "    #    {on_h_axis} by {on_w_axis} by {on_d_axis}.')\n",
    "    return (int(on_h_axis), int(on_w_axis), on_d_axis)\n",
    "\n",
    "def convolutional_layer1(img, filter_size, stride, padding, K):\n",
    "    \"\"\"\n",
    "        Receives a image (H*W*3)\n",
    "        The kernel size is filter_size*filter_size*3\n",
    "        The weights are learned by the CNN where each \"slice\" is a filter\n",
    "        The depth of the output map is represented by K\n",
    "\n",
    "        Returns:\n",
    "            Activation map applying the filter to the input\n",
    "    \"\"\"\n",
    "    weights = np.random.rand(K, filter_size, filter_size, img.shape[2])\n",
    "    biases = np.random.rand(K, 1)\n",
    "    print(f'The weights shape is {weights.shape} and biases shape is {biases.shape}')\n",
    "    print(weights[0,:,:,:].shape) # filter0 or weight0\n",
    "\n",
    "    out_dims = assess_output_vol(img.shape, filter_size, stride, padding,K)\n",
    "\n",
    "    activation_map = np.zeros(out_dims)\n",
    "    assert activation_map.shape == out_dims\n",
    "\n",
    "    for d in range(out_dims[2]):\n",
    "        for i in range(0,out_dims[0],stride):\n",
    "            for j in range(0,out_dims[1],stride):\n",
    "                activation_map[int(i/4),int(j/4),d] = np.sum(img[i:i+filter_size,j:j+filter_size,:] * weights[d:,:,:]) + biases[d]\n",
    "    \n",
    "    print(f'The output volume shape is {activation_map.shape}\\n')\n",
    "\n",
    "    return activation_map\n",
    "\n",
    "K = 10 # depth of output map\n",
    "\n",
    "# Testing for suitable strides\n",
    "assess_output_vol((11,11,3), 5, 2, [0,0], K)\n",
    "assess_output_vol(img.shape, 22, 4, [21/2,1], K)\n",
    "# Passing the image through a basic convolution layer\n",
    "activn_map = convolutional_layer1(img, 22, 4, [21/2,1], K)\n",
    "print(activn_map[:2,:2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(2, 2, 10)\n"
     ]
    }
   ],
   "source": []
  }
 ]
}